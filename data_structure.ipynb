{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Create data file structures and sets:\n",
    "\n",
    "This script creates csv files with file names and labels for all used data sets.\n",
    "The tensorflow pipeline reads the csv files later and imports images in batches.\n",
    "\n",
    "Used data sets:\n",
    "    - intrinsic imigas in the wild (iiw)\n",
    "    - MPI Sintel data set\n",
    "    - MIT data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-03T13:02:53.560693Z",
     "start_time": "2017-06-03T13:02:53.135735Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-03T13:02:53.567060Z",
     "start_time": "2017-06-03T13:02:53.562985Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# directory where to save csv files:\n",
    "save_csvs = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-03T13:02:53.654931Z",
     "start_time": "2017-06-03T13:02:53.571863Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def create_datasets(df, p_train, p_valid, p_test, sample=True):\n",
    "    \"\"\"\n",
    "    Splits a data set df into training, validation and testing data set with relative cardinality\n",
    "    p_train, p_valid and p_test, respectively.\n",
    "    :param df: complete data set which should be split into training, validation and testing sets\n",
    "    :type df: pd.DataFrame()\n",
    "    :param p_train: relative cardinality of training data set\n",
    "    :type p_train: float (\\elem [0,1])\n",
    "    :param p_valid: relative cardinality of validation data set\n",
    "    :type p_valid: float (\\elem [0,1])\n",
    "    :param p_test: relative cardinality of testing data set\n",
    "    :type p_test: float (\\elem [0,1])\n",
    "    :return: training, validation and testing data sets\n",
    "    :type: [pd.DataFrame, pd.DataFrame, pd.DataFrame]\n",
    "    \"\"\"\n",
    "    # make sure we have consistancy:\n",
    "    assert p_train + p_valid + p_test  == 1, 'p_train, p_valid, p_test must add up to 1'\n",
    "    # this data set will be the training data set in the end:\n",
    "    df_train = df.copy()\n",
    "    # sampling data to get testing set:\n",
    "    df_test = df_train.sample(n=int(p_test * df.shape[0]), frac=None, replace=False, weights=None, random_state=42, axis=0)\n",
    "    # drop these sampled test data (we do not want them in the other data sets):\n",
    "    df_train.drop(df_test.index, inplace=True)\n",
    "    # sampling data to get validation set:\n",
    "    df_valid = df_train.sample(n=int(p_valid * df.shape[0]), frac=None, replace=False, weights=None, random_state=42, axis=0)\n",
    "    # drop these sampled valid data (we do not want them in the training set):\n",
    "    df_train.drop(df_valid.index, inplace=True)\n",
    "    \n",
    "    if sample:\n",
    "        # now create sample files:\n",
    "        df_train_sample = df_train.sample(n=50, frac=None, replace=False, weights=None, random_state=42, axis=0)\n",
    "        df_valid_sample = df_valid.sample(n=20, frac=None, replace=False, weights=None, random_state=42, axis=0)\n",
    "        df_test_sample = df_test.sample(n=20, frac=None, replace=False, weights=None, random_state=42, axis=0)\n",
    "    else:\n",
    "        df_train_sample = pd.DataFrame()\n",
    "        df_valid_sample = pd.DataFrame()\n",
    "        df_test_sample = pd.DataFrame()\n",
    "    # print info:\n",
    "    print(f'data set cardinalities:\\n' +\n",
    "          f'    # complete data set: {len(df)}\\n' +\n",
    "          f'    # training data set: {len(df_train)}\\n' +\n",
    "          f'    # validation data set: {len(df_valid)}\\n' +\n",
    "          f'    # testing data set: {len(df_test)}\\n' +\n",
    "          f'    # sample training data set: {len(df_train_sample)}\\n' +\n",
    "          f'    # sample validation data set: {len(df_valid_sample)}\\n' +\n",
    "          f'    # sample testing data set: {len(df_test_sample)}'\n",
    "         )\n",
    "    return df_train, df_valid, df_test, df_train_sample, df_valid_sample, df_test_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Data set iiw:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-03T13:02:53.661700Z",
     "start_time": "2017-06-03T13:02:53.657162Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# directory of data\n",
    "data_dir_iiw = 'data/iiw-dataset/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-03T13:02:54.458117Z",
     "start_time": "2017-06-03T13:02:53.665464Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# import file names of data directory:\n",
    "df_iiw = pd.DataFrame([[int(os.path.splitext(os.path.basename(x))[0]), \n",
    "                        os.path.relpath(x, save_csvs), \n",
    "                        os.path.splitext(os.path.relpath(x, save_csvs))[0]+'.json'] for x in glob.glob(data_dir_iiw + '/*.png')], \n",
    "                      columns=['file_id', 'image_path', 'label_path'])\n",
    "# sort by file ids (we can sort these files because they are shuffled during training in tf anyways):\n",
    "df_iiw.sort_values(by='file_id', inplace=True)\n",
    "# reset indices of pd.DataFrame:\n",
    "df_iiw.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-03T13:02:54.478115Z",
     "start_time": "2017-06-03T13:02:54.461055Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data set cardinalities:\n",
      "    # complete data set: 5230\n",
      "    # training data set: 4184\n",
      "    # validation data set: 523\n",
      "    # testing data set: 523\n",
      "    # sample training data set: 50\n",
      "    # sample validation data set: 20\n",
      "    # sample testing data set: 20\n"
     ]
    }
   ],
   "source": [
    "# get training validation and testing data set of the iiw data:\n",
    "df_iiw_train, df_iiw_valid, df_iiw_test, df_iiw_train_sample, df_iiw_valid_sample, df_iiw_test_sample = create_datasets(df=df_iiw,\n",
    "                                                                                                                        p_train=0.8, \n",
    "                                                                                                                        p_valid=0.1, \n",
    "                                                                                                                        p_test=0.1,\n",
    "                                                                                                                        sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-03T13:02:54.560124Z",
     "start_time": "2017-06-03T13:02:54.481071Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save complete data set, training data set, validation data set and testing data set in separate data files:\n",
    "df_iiw.to_csv(path_or_buf=save_csvs + 'data_iiw_complete.csv', sep=',', columns=['image_path', 'label_path'], index=False, header=False)\n",
    "df_iiw_train.to_csv(path_or_buf=save_csvs + 'data_iiw_train.csv', sep=',', columns=['image_path', 'label_path'], index=False, header=False)\n",
    "df_iiw_valid.to_csv(path_or_buf=save_csvs + 'data_iiw_valid.csv', sep=',', columns=['image_path', 'label_path'], index=False, header=False)\n",
    "df_iiw_test.to_csv(path_or_buf=save_csvs + 'data_iiw_test.csv', sep=',', columns=['image_path', 'label_path'], index=False, header=False)\n",
    "\n",
    "df_iiw_train_sample.to_csv(path_or_buf=save_csvs + 'sample_data_iiw_train.csv', sep=',', \n",
    "                           columns=['image_path', 'label_path'], index=False, header=False)\n",
    "df_iiw_valid_sample.to_csv(path_or_buf=save_csvs + 'sample_data_iiw_valid.csv', sep=',',\n",
    "                           columns=['image_path', 'label_path'], index=False, header=False)\n",
    "df_iiw_test_sample.to_csv(path_or_buf=save_csvs + 'sample_data_iiw_test.csv', sep=',', \n",
    "                          columns=['image_path', 'label_path'], index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Sintel data set (data general -> use clean and albedo):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-03T13:02:54.567455Z",
     "start_time": "2017-06-03T13:02:54.562739Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "data_dir_sintel = 'data/mpi-sintel-complete/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-03T13:02:54.733481Z",
     "start_time": "2017-06-03T13:02:54.570759Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# use 'clean pass' images (see narihira2015: p.3: \"'final images' [...] are the result of additional computer \n",
    "# graphics tricks which dristract from our application.\"):\n",
    "df_sintel = pd.DataFrame([[os.path.relpath(x, save_csvs), \n",
    "                           os.path.relpath(x, save_csvs).replace('clean', 'albedo')\n",
    "                          ] for x in glob.glob(data_dir_sintel + 'training/clean/**/*.png')],\n",
    "                         columns=['image_path', 'label_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-03T13:02:54.748476Z",
     "start_time": "2017-06-03T13:02:54.736470Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data set cardinalities:\n",
      "    # complete data set: 1064\n",
      "    # training data set: 852\n",
      "    # validation data set: 106\n",
      "    # testing data set: 106\n",
      "    # sample training data set: 50\n",
      "    # sample validation data set: 20\n",
      "    # sample testing data set: 20\n"
     ]
    }
   ],
   "source": [
    "# get training validation and testing data set of the mpi-sintel data:\n",
    "df_sintel_train, df_sintel_valid, df_sintel_test, \\\n",
    "    df_sintel_train_sample, df_sintel_valid_sample, df_sintel_test_sample = create_datasets(df=df_sintel, \n",
    "                                                                                            p_train=0.8,\n",
    "                                                                                            p_valid=0.1, \n",
    "                                                                                            p_test=0.1,\n",
    "                                                                                            sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-03T13:02:54.803307Z",
     "start_time": "2017-06-03T13:02:54.751780Z"
    },
    "code_folding": [],
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# save complete data set, training data set, validation data set and testing data set in separate data files:\n",
    "df_sintel.to_csv(path_or_buf=save_csvs + 'data_sintel_complete.csv', sep=',',\n",
    "                 columns=['image_path', 'label_path'], index=False, header=False)\n",
    "df_sintel_train.to_csv(path_or_buf=save_csvs + 'data_sintel_train.csv', sep=',',\n",
    "                       columns=['image_path', 'label_path'], index=False, header=False)\n",
    "df_sintel_valid.to_csv(path_or_buf=save_csvs + 'data_sintel_valid.csv', sep=',', \n",
    "                       columns=['image_path', 'label_path'], index=False, header=False)\n",
    "df_sintel_test.to_csv(path_or_buf=save_csvs + 'data_sintel_test.csv', sep=',', \n",
    "                      columns=['image_path', 'label_path'], index=False, header=False)\n",
    "\n",
    "df_sintel_train_sample.to_csv(path_or_buf=save_csvs + 'sample_data_sintel_train.csv', sep=',',\n",
    "                              columns=['image_path', 'label_path'], index=False, header=False)\n",
    "df_sintel_valid_sample.to_csv(path_or_buf=save_csvs + 'sample_data_sintel_valid.csv', sep=',', \n",
    "                              columns=['image_path', 'label_path'], index=False, header=False)\n",
    "df_sintel_test_sample.to_csv(path_or_buf=save_csvs + 'sample_data_sintel_test.csv', sep=',', \n",
    "                             columns=['image_path', 'label_path'], index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-03T13:02:54.863338Z",
     "start_time": "2017-06-03T13:02:54.806600Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# also save (unknown) test files:\n",
    "df_sintel_test_unknown = pd.DataFrame([[os.path.relpath(x, save_csvs),\n",
    "                                        None\n",
    "                                       ] for x in glob.glob(data_dir_sintel + 'test/clean/**/*.png')],\n",
    "                                      columns=['image_path', 'label_path'])\n",
    "df_sintel_test_unknown.to_csv(path_or_buf=save_csvs + 'data_sintel_test_unknown.csv', sep=',',\n",
    "                              columns=['image_path', 'label_path'], index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sintel data set (data general -> use clean_noshadingtextures, albedo_noshadingtextures and shading):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-06T15:43:06.087141Z",
     "start_time": "2017-06-06T15:43:05.555248Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use 'clean pass' images (see narihira2015: p.3: \"'final images' [...] are the result of additional computer \n",
    "# graphics tricks which dristract from our application.\"):\n",
    "df_sintel2 = pd.DataFrame([[os.path.relpath(x, save_csvs), \n",
    "                            os.path.relpath(x, save_csvs).replace('clean_noshadingtextures', 'albedo_noshadingtextures'),\n",
    "                            os.path.relpath(x, save_csvs).replace('clean_noshadingtextures', 'shading'),\n",
    "                           ] for x in glob.glob(data_dir_sintel + 'training/clean_noshadingtextures/**/*.png')],\n",
    "                          columns=['image_path', 'albedo_label_path', 'shading_label_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-06T15:44:49.358025Z",
     "start_time": "2017-06-06T15:44:49.332744Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data set cardinalities:\n",
      "    # complete data set: 1014\n",
      "    # training data set: 812\n",
      "    # validation data set: 101\n",
      "    # testing data set: 101\n",
      "    # sample training data set: 50\n",
      "    # sample validation data set: 20\n",
      "    # sample testing data set: 20\n"
     ]
    }
   ],
   "source": [
    "# get training validation and testing data set of the mpi-sintel data:\n",
    "df_sintel_train2, df_sintel_valid2, df_sintel_test2, \\\n",
    "    df_sintel_train_sample2, df_sintel_valid_sample2, df_sintel_test_sample2 = create_datasets(df=df_sintel2, \n",
    "                                                                                               p_train=0.8,\n",
    "                                                                                               p_valid=0.1, \n",
    "                                                                                               p_test=0.1,\n",
    "                                                                                               sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-06T15:51:40.110349Z",
     "start_time": "2017-06-06T15:51:40.019198Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save complete data set, training data set, validation data set and testing data set in separate data files:\n",
    "df_sintel2.to_csv(path_or_buf=save_csvs + 'data_sintel_shading_complete.csv', sep=',',\n",
    "                  columns=['image_path', 'albedo_label_path', 'shading_label_path'], index=False, header=False)\n",
    "df_sintel_train2.to_csv(path_or_buf=save_csvs + 'data_sintel_shading_train.csv', sep=',',\n",
    "                        columns=['image_path', 'albedo_label_path', 'shading_label_path'], index=False, header=False)\n",
    "df_sintel_valid2.to_csv(path_or_buf=save_csvs + 'data_sintel_shading_valid.csv', sep=',', \n",
    "                        columns=['image_path', 'albedo_label_path', 'shading_label_path'], index=False, header=False)\n",
    "df_sintel_test2.to_csv(path_or_buf=save_csvs + 'data_sintel_shading_test.csv', sep=',', \n",
    "                       columns=['image_path', 'albedo_label_path', 'shading_label_path'], index=False, header=False)\n",
    "\n",
    "df_sintel_train_sample2.to_csv(path_or_buf=save_csvs + 'sample_data_sintel_shading_train.csv', sep=',',\n",
    "                               columns=['image_path', 'albedo_label_path', 'shading_label_path'], index=False, header=False)\n",
    "df_sintel_valid_sample2.to_csv(path_or_buf=save_csvs + 'sample_data_sintel_shading_valid.csv', sep=',', \n",
    "                               columns=['image_path', 'albedo_label_path', 'shading_label_path'], index=False, header=False)\n",
    "df_sintel_test_sample2.to_csv(path_or_buf=save_csvs + 'sample_data_sintel_shading_test.csv', sep=',', \n",
    "                              columns=['image_path', 'albedo_label_path', 'shading_label_path'], index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## MIT data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-03T13:02:54.869647Z",
     "start_time": "2017-06-03T13:02:54.865599Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "data_dir_mit = 'data/mit_intrinsic/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-03T13:02:54.889226Z",
     "start_time": "2017-06-03T13:02:54.873083Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "df_mit = pd.DataFrame([[os.path.relpath(x, save_csvs), \n",
    "                        os.path.relpath(x, save_csvs).replace('original', 'reflectance'), \n",
    "                        os.path.relpath(x, save_csvs).replace('original', 'shading')\n",
    "                       ] for x in glob.glob(data_dir_mit + '**/original.png')],\n",
    "                      columns=['image_path', 'albedo_label_path', 'shading_label_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-03T13:02:54.902926Z",
     "start_time": "2017-06-03T13:02:54.891727Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data set cardinalities:\n",
      "    # complete data set: 20\n",
      "    # training data set: 16\n",
      "    # validation data set: 2\n",
      "    # testing data set: 2\n",
      "    # sample training data set: 0\n",
      "    # sample validation data set: 0\n",
      "    # sample testing data set: 0\n"
     ]
    }
   ],
   "source": [
    "# get training validation and testing data set of the mit data:\n",
    "df_mit_train, df_mit_valid, df_mit_test, _, _, _ = create_datasets(df=df_mit, p_train=0.8, \n",
    "                                                                   p_valid=0.1, p_test=0.1, sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-03T13:02:54.928035Z",
     "start_time": "2017-06-03T13:02:54.906147Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# save complete data set, training data set, validation data set and testing data set in separate data files:\n",
    "df_mit.to_csv(path_or_buf=save_csvs + 'data_mit_complete.csv', sep=',', \n",
    "              columns=['image_path', 'albedo_label_path', 'shading_label_path'], index=False, header=False)\n",
    "df_mit_train.to_csv(path_or_buf=save_csvs + 'data_mit_train.csv', sep=',', \n",
    "                    columns=['image_path', 'albedo_label_path', 'shading_label_path'], index=False, header=False)\n",
    "df_mit_valid.to_csv(path_or_buf=save_csvs + 'data_mit_valid.csv', sep=',', \n",
    "                    columns=['image_path', 'albedo_label_path', 'shading_label_path'], index=False, header=False)\n",
    "df_mit_test.to_csv(path_or_buf=save_csvs + 'data_mit_test.csv', sep=',', \n",
    "                   columns=['image_path', 'albedo_label_path', 'shading_label_path'], index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "84px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
